{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12d0fac9-d494-47ff-ab79-12e7c1830195",
   "metadata": {},
   "source": [
    "# Stand-up comedy topic modeling across cultures\n",
    "## Natural Language Processing (E1282) Research Note, Dr. Sascha GÃ¶bel\n",
    "- Author: Lonny Chen (216697)\n",
    "- Submission Date: 5 January 2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9babe3-d6d1-4ac7-987a-cf5dc7761379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local environment\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8663ff89-e3c6-4fc0-8039-97a7876e9dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data.data_collection import get_channels_shorts_video_ids, get_transcript_from_video_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621382f2-10c4-4bd6-885f-5ae7bc6ba029",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "### Step 1: Get YouTube video IDs\n",
    "- Use of [YT-DLP](https://github.com/yt-dlp/yt-dlp) for extracting video information is referenced from [StandUp4AI](https://github.com/Standup4AI/dataset/) project code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c9a6f4-dfd7-427b-9569-c31095e10eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel @standup extracted 404 videos from https://www.youtube.com/@standup/shorts\n",
      "Channel @comedycentraluk extracted 375 videos from https://www.youtube.com/@comedycentraluk/search?query=standup\n",
      "CPU times: user 2.83 s, sys: 78.6 ms, total: 2.91 s\n",
      "Wall time: 13.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lonnychen/Dropbox/@project - HERTIE SCHOOL/3. NLP (E1282)/A3. Research Note/nlp_research_note/data/data_collection.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat(df_channels_list)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Input YouTube channel search information here\n",
    "channels = [\n",
    "    {\n",
    "        'channel': 'Comedy Central Stand-Up',\n",
    "        'search_url': 'https://www.youtube.com/@standup/shorts',\n",
    "        'list_search_str': [],\n",
    "        'language_code': 'en'\n",
    "    },\n",
    "    {\n",
    "        'channel': 'Comedy Central UK',\n",
    "        'search_url': 'https://www.youtube.com/@comedycentraluk/search?query=standup',\n",
    "        'list_search_str': [],\n",
    "        'language_code': 'en'\n",
    "    }\n",
    "]\n",
    "df_channels = get_channels_shorts_video_ids(channels=channels)\n",
    "#df_channels.to_csv('data/df_channels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef56bd5-4818-4075-a622-dfade174eed2",
   "metadata": {},
   "source": [
    "### Step 2: Get transcript strings from video IDs\n",
    "- Use [YouTube Transcript API](https://github.com/jdepoix/youtube-transcript-api) to fetch correct language transcripts\n",
    "- Internally uses \"Rotating Residential Proxy\" from [Webshare](https://www.webshare.io/?referral_code=w0xno53eb50g) to workaround <span style=\"color:red\">IpBlocked</span> exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57f75a97-d7e3-4c41-86d5-16adc99b7e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetch completed for video 'JYjRBzuVFwQ'\n",
      "CPU times: user 108 ms, sys: 21.1 ms, total: 129 ms\n",
      "Wall time: 6.36 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"it was great being in a relationship\\nwith her but I didn't know like Latino\\nwomen like I didn't know that like\\nyou're under investigation like it's\\njust when you date a Puerto Rican girl\\nyou need to have the answers quick you\\nneed to like have facts right away\\nbecause they will interrogate you and if\\nyou don't have the answers quick you\\nlook like a liar and they watch men they\\nare designed to watch men watching\\nwaiting that's what they do they make\\nexcellent NFL referees I think if you\\nhad Puerto Rican girls reing the games\\nyou'd have zero Miss calls the whole\\nseason because they see everything so\\nthat's just what could you imagine they\\nwere the refs they would be right there\\nlike um you out of bound stupid no\\nno I mean for real you out of\\nbounds I don't need instant replay I I\\ninstantly saw you step out of bound so\\nyou\\nknow I mean I don't even know the rules\\njust go home\\nbye you out the game\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# TEST: one transcript fetch\n",
    "video_id = 'JYjRBzuVFwQ' #test shorts\n",
    "get_transcript_from_video_id(video_id, 'en', use_proxy=True)\n",
    "\n",
    "# TEST: various tasks using small sample of videos\n",
    "#df_test = df_channels[0:5].copy()\n",
    "#df_test['transcript'] = df_test.apply(lambda row: get_transcript_from_video_id(row['video_id'], row['language_code']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086a8ebb-b5aa-4aab-a582-78556ec4ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# FULL set of videos (2-3 hours for n=~770)\n",
    "df_channels['transcript'] = df_channels.apply(lambda row: get_transcript_from_video_id(row['video_id'], row['language_code']), axis=1)\n",
    "# Save to CSV\n",
    "df_channels.to_csv('data/df_channels_transcripts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ebd688d-298e-4611-a509-b370b7473168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read from saved CSV\n",
    "df_channels_load = pd.read_csv('data/df_channels_transcripts.csv')\n",
    "df_channels_load.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
